---
title: "GLM Model"
author: "Danielle van Os"
date: "06/01/2021"
output: 
  html_document:
    code_folding: hide
---

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(stats) # For linear models
library(MASS) # For random data generation with exact means 
library(knitr) # for nice tables

rm(list = ls())
```

## GLM Parameters 

* Number of variables
* number of groups per variable 
* mean for each group/s 
* sd for each group/s
* presence of continuous variable (e.g., for ANCOVA)



## Linear Model - 1 predictor 

### Generate sample data 

To make it faster consider running the lm model, saving it, and adding aspects of that to the graph, rather than running the lm model twice. 
```{r}

# Parameters 
sample_size <- 400
intercept <- 10
slope <- 3.4
sd <- 5
mean <- 0

x <- mvrnorm(n = sample_size, mu = 0, Sigma = sd, empirical = TRUE) 
y <- intercept + slope*x + mvrnorm(n = sample_size, mu = 0, Sigma = sd, empirical = TRUE) 
df <- tibble(x = x, y = y)

lm <- summary(lm(formula = y ~ x, data = df))

```

### Plot Linear Model

```{r}

ggplot(data = df, mapping = aes(x = x, y = y)) + 
  geom_point() + 
  stat_smooth(method = "lm")
```

## t-test - 1 variable 2 groups

```{r}
# Parameters
group_size <- 200 
mean_g1 <- 10
mean_g2 <- 12
sd_g1 <- 0.3
sd_g2 <- 0.3

# Data generation
group_1 <- mvrnorm(n = group_size, mu = mean_g1, Sigma = sd_g1, empirical = TRUE)
group_2 <- mvrnorm(n = group_size, mu = mean_g2, Sigma = sd_g2, empirical = TRUE)
data <- c(group_1, group_2)

# Data frame
df <- tibble(group = rep(c(0, 1), each = group_size),
             y = data)

# Linear model and t.test function 
t.test(formula = y ~ group, data = df)
t_test <- summary(lm(formula = y ~ 1 + group, data = df)) # The '1' is a way of writing 1*B0 or 1*intercept, which in this case is 1*10. 

# Output
t_test

knitr::kable(coefficients(t_test), digits=3)

```
The x estimate indicates the amount that the second group mean differs from the first. If it is negative it means that the mean of the second group is less than that of the first group, whereas if it is positive, the mean of the second group is greater than that of hte first group. 

### Plot T-Test 

NOTE TO SELF: Eventually animate the transition from a standard graph to the density plots 
NOTE 2: add intercept horizontal line as well 

```{r graph t-test}

# Step 1 - standard graph
ggplot(data = df, mapping = aes(x =group, y = y)) + 
  geom_point() + 
  stat_smooth(method = "lm")

# Step 2 - change axes 
ggplot(data = df, mapping = aes(x = y, y =group)) + 
  geom_point() + 
  stat_smooth(method = "lm")

# Step 3 - remove regression line 
ggplot(data = df, mapping = aes(x = y, y =group)) + 
  geom_point() 

# Step 4 - change colours 
ggplot(data = df, mapping = aes(x = y, y =group, color =group)) + 
  geom_point(alpha = 0.5) + 
  theme(legend.position = "none")

# Step 5 - move dots from second graph to the x axis 
ggplot(data = df, mapping = aes(x = y, y = 0, color =group)) + 
  geom_point(alpha = 0.5) + 
  ylim(0, 1) + 
  theme(legend.position = "none")

# Step 6 - turn into density plots for easier viewing (how t-tests are usually displayed)
ggplot(data = df, aes(x = y, group =group, fill =group)) + 
  geom_density(alpha = 0.5) + 
  theme(legend.position = "none")

```


## ANOVA - 3 groups 

```{r anova}
# Parameters
group_size <- 200 
mean_g1 <- 10
mean_g2 <- 12
mean_g3 <- 7
sd_g1 <- 0.3
sd_g2 <- 0.3
sd_g3 <- 0.3 

# Data generation
group_1 <- mvrnorm(n = group_size, mu = mean_g1, Sigma = sd_g1, empirical = TRUE)
group_2 <- mvrnorm(n = group_size, mu = mean_g2, Sigma = sd_g2, empirical = TRUE)
group_3 <- mvrnorm(n = group_size, mu = mean_g3, Sigma = sd_g3, empirical = TRUE)
data <- c(group_1, group_2, group_3)

# Data frame
df <- tibble(group_label = rep(c("group_1", "group_2", "group_3"), each = group_size),
             group_n = as_factor(rep(c(0, 1, 2), each = group_size)),
             group_2 = rep(c(0,1,0), each = group_size), 
             group_3 = rep(c(0,0,1), each = group_size),
             y = data)

# Linear model and anova function 
summary(aov(y ~ group_label, data = df))

anova <- summary(lm(formula = y ~ 1 + group_2 + group_3, data = df))

# Output
anova

knitr::kable(coefficients(anova), digits=3)

```

What is a t-test not simply an ANOVA with two groups, or an ANOVA simply a t-test with 3+ groups? 

### Plot ANOVA 

```{r graph_anova}

# Step 1 - standard graph
ggplot(data = df, mapping = aes(x = group_n, y = y)) + 
  geom_point() 

# Step 2 - change axes 
ggplot(data = df, mapping = aes(x = y, y = group_n)) + 
  geom_point() 

# Step 3 - remove regression line 
ggplot(data = df, mapping = aes(x = y, y = group_n)) + 
  geom_point() 

# Step 4 - change colours 
ggplot(data = df, mapping = aes(x = y, y = group_n, color = group_n)) + 
  geom_point(alpha = 0.5) + 
  theme(legend.position = "none")

# Step 5 - move dots from second graph to the x axis 
ggplot(data = df, mapping = aes(x = y, y = 0, color = group_n)) + 
  geom_point(alpha = 0.5) + 
  ylim(0, 1) + 
  theme(legend.position = "none")

# Step 6 - turn into density plots for easier viewing (how t-tests are usually displayed)
ggplot(data = df, aes(x = y, group = group_label, fill = group_label)) + 
  geom_density(alpha = 0.5) 

```

### Two-way/Factorial ANOVA 

The model for a two-way ANOVA with interactions includes:

* Main effect of variable 1   
* Main effect of variable 2  
* Interactions between each level of variable 1 and level 2  
* error 

#### Example equations

##### Example 1 - 2x3 with interaction
Variable 1 has two levels, variable 2 has three levels, with an interaction term:

$$ y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \beta_3X_1X_2 $$
Where:

* $\beta_0$ is the grand mean, or the mean for the first level of all factors  
* $X_1$ is the score on variable 1 
* $X_2$ is the score on variable 2 
* $\beta$ represents the slope or beta value 

NOTE TO SELF: CHANGE THE CODE BELOW SO THERE IS AN OPTION TO HAVE INTERACTIONS OR NO INTERACTION    

What is an interaction? Broadly, it suggests that the effect of one predictor variable on the outcome variable is dependent on the other predictor. 

```{r}
# THE ISSUE WITH THIS WAY IS THAT VAR1 AND VAR2 ARE ADDED TOGETHER TO CREATE A SINGLE VALUE (RANDOM, NO PARTICULAR REASON, I JUST NEEDED A SINGLE VALUE) BUT ADDING THEM MEANS THEY'RE SINGULAR SO COME UP WITH AN ALTERNATIVE WAY TO MODEL BELOW 
# Parameters
total_sample_size <- 600

var1_nvar <- 2
var1_g1_mean <- 10
var1_g2_mean <- 12
var1_g1_sd <- 0.3
var1_g2_sd <- 0.3
 
var2_nvar <- 3
var2_g1_mean <- 3
var2_g2_mean <- 6
var2_g3_mean <- 8
var2_g1_sd <- 0.3
var2_g2_sd <- 0.3
var2_g3_sd <- 0.3 

 

# Data generation
var1_g1 <- mvrnorm(n = round(total_sample_size/var1_nvar), mu = var1_g1_mean, Sigma = var1_g1_sd, empirical = TRUE)
var1_g2 <- mvrnorm(n = round(total_sample_size/var1_nvar), mu = var1_g2_mean, Sigma = var1_g2_sd, empirical = TRUE)
var1 <- c(var1_g1, var1_g2)

var2_g1 <- mvrnorm(n = round(total_sample_size/var2_nvar), mu = var2_g1_mean, Sigma = var2_g1_sd, empirical = TRUE)
var2_g2 <- mvrnorm(n = round(total_sample_size/var2_nvar), mu = var2_g2_mean, Sigma = var2_g2_sd, empirical = TRUE)
var2_g3 <- mvrnorm(n = round(total_sample_size/var2_nvar), mu = var2_g3_mean, Sigma = var2_g3_sd, empirical = TRUE)
var2 <- c(var2_g1, var2_g2, var2_g3)

# Data frame
df <- tibble(var1_label = rep(c("group_1", "group_2"), each = total_sample_size/var1_nvar),
             var2_label = rep(c("group_1", "group_2", "group_3"), each = total_sample_size/var2_nvar),
             
             y = c(var1 + var2),
             
             var1_group_n = as_factor(rep(c(1, 2), each = total_sample_size/var1_nvar)),
             var2_group_n = as_factor(rep(c(1, 2, 3), each = total_sample_size/var2_nvar)),
             
             var1_g2 = ifelse(var1_label == "group_2", 1, 0),
             var2_g2 = ifelse(var2_label == "group_2", 1, 0),
             var2_g3 = ifelse(var2_label == "group_3", 1, 0)
             )

# Linear model and anova function 
summary(aov(y ~ var1_label + var2_label, data = df))

fact_anova1 <- summary(lm(formula = y ~ 1 + var1_g2 + var2_g2 + var2_g3 + var1_g2*var2_g2 + var1_g2*var2_g3, data = df))
fact_anova2 <- summary(lm(formula = y ~ var1_label * var2_label, data = df))

fact_anova1
fact_anova2
# Output
anova

knitr::kable(coefficients(anova), digits=3)
```

```{r}

# Set coefficients
alpha = 10
beta1 = .3
beta2 = -.5
beta3 = -1.1

# Generate 200 trials
A = c(rep(c(0), 100), rep(c(1), 100)) # '0' 100 times, '1' 100 times
B = rep(c(rep(c(0), 50), rep(c(1), 50)), 2) # '0'x50, '1'x50, '0'x50, '1'x50
e = rnorm(200, 0, sd=1) # Random noise, with standard deviation of 1

# Generate your data using the regression equation
y = alpha + beta1*A + beta2*B + beta3*A*B + e

y = 1*alpha + var1_g2 + var2_g2 + var2_g3 + var1_g2*var2_g2 + var1_g2*var2_g3

# Join the variables in a data frame
data = tibble(A, 
              B, 
              y,
              A_g2 = ifelse(A == 1, 1, 0),
              B_g2 = ifelse(B == 1, 1, 0),
              B_g3 = ifelse(B == 2, 1, 0))

# Fit an ANOVA
model = aov(y ~ A*B, data=data)
summary(model)

# Linear model equivalent 
"A"
A
"B"
B
```

In R it is written as follows: 
```{r class.source = 'fold-show', eval = FALSE}

lm(outcome_var ~ 1 + # the 1 is included to indicate $1*B0/intercept
   var1_level2 + var2_level2 + var2_level3 + # main effects 
     var1_level2*var2_level2 + var1_level2*var2_level3) # interaction terms 
  
```


Note the first group on both variables is not included.

##### - 2x3 without interaction


##### - 4x5 with interaction

It quickly gets difficult to model each 



### ANCOVA - multiple groups (categorical) and a continuous predictor

ANCOVA is an extension of ANOVA where you control for one or more covariates.

A covariate is a continuous variable that is correlated with the dependent variable but is not the focus of the study.

In an ANOVA, the variance due to covariates becomes error. If it is controlled in an ANCOVA, then the error variance is less, so you more accurately assess the variance
due to the factor (the IV).

Assumptions:  

* **ANOVA assumptions - normality and homogeneity of variance**
* **Linearity between pairs of covariates** - if there is more than one covariate
* **Linearity between the covariates and the DV** 
* **Homogeneity of regression** - the regression slope between the continuous predictor and outcome variable should be the same for all groups, or there should be no interaction between the continuous predictor and group levels in predicting the outcome variable. 
* **Independence of covariate and factor** - the categorical and continuous predictors should be independent 

Equation ANCOVA: y (person's score) = intercept for group 1 + intercept for each group + 
Equation MLM: y (person's score) = (general intercept + random intercept for each group) + (general regression term/slope + random slope for each group) + error 

```{r ancova}
# Parameters
group_size <- 200 
mean_g1 <- 10
mean_g2 <- 12
mean_g3 <- 7
sd_g1 <- 0.3
sd_g2 <- 0.3
sd_g3 <- 0.3 
n_groups <- 3

# Data generation
group_1 <- mvrnorm(n = group_size, mu = mean_g1, Sigma = sd_g1, empirical = TRUE)
group_2 <- mvrnorm(n = group_size, mu = mean_g2, Sigma = sd_g2, empirical = TRUE)
group_3 <- mvrnorm(n = group_size, mu = mean_g3, Sigma = sd_g3, empirical = TRUE)
data <- c(group_1, group_2, group_3)
continuous <-data + mvrnorm(n = group_size*n_groups, mu = 0, Sigma = 2, empirical = TRUE)

# Data frame
df <- tibble(group_label = rep(c("group_1", "group_2", "group_3"), each = group_size),
             group_n = as_factor(rep(c(0, 1, 2), each = group_size)),
             group_2 = rep(c(0,1,0), each = group_size), 
             group_3 = rep(c(0,0,1), each = group_size),
             y = data,
             x = continuous)
```

```{r}

ggplot(data = df, mapping = aes(x = x, y = y)) + 
  geom_point() 

```
















